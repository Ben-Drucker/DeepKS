{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Science Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os, matplotlib.pyplot as plt, numpy as np, collections, tqdm, textwrap as tw, random\n",
    "import sklearn.metrics as metrics\n",
    "from matplotlib import rcParams\n",
    "from matplotlib.markers import MarkerStyle\n",
    "rcParams['font.family'] = \"P052\"\n",
    "try:\n",
    "    pass\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2\n",
    "    %config InlineBackend.figure_format = 'svg'\n",
    "except SyntaxError:\n",
    "    pass\n",
    "\n",
    "os.chdir(\"/Users/druc594/Library/CloudStorage/OneDrive-PNNL/Desktop/DeepKS_/DeepKS/discovery/nature_atlas/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Freedman_Diaconis_rule_n_bins = lambda x: int(round(((max(x) - min(x))/(2*(np.percentile(x, 75) - np.percentile(x, 25))*len(x)**(-1/3))), 0))\n",
    "\n",
    "normalize_ranks = lambda obj_to_norm, starting_ranks, ending_ranks: obj_to_norm*(ending_ranks-1)/(starting_ranks-1) + (starting_ranks-ending_ranks)/(starting_ranks-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "their_ranks = pd.read_csv(\"./their_ranks.csv\", index_col=0)\n",
    "our_ranks = pd.read_csv(\"./our_ranks.csv\", index_col=0)\n",
    "their_percentiles = pd.read_csv(\"./their_percentiles.csv\", index_col=0)\n",
    "our_percentiles = pd.read_csv(\"./our_percentiles.csv\", index_col=0)\n",
    "our_raw_scores = pd.read_csv(\"./our_raw_scores.csv\", index_col=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a \"Pseudo\" confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "# Pseudo Confusion Matrix: Cell (X, Y) will be \n",
    "# incremented when a site has rank >= K for their kinase X, our kinase Y.\n",
    "# Initialize np array of zeros, of shape (num_their_kins, num_our_kins)\n",
    "num_their_kins = len(their_ranks.columns)\n",
    "num_our_kins = len(our_ranks.columns)\n",
    "assert num_their_kins == num_our_kins, \"The number of kinases in our ranks and their ranks are not the same\"\n",
    "assert K <= num_their_kins, \"K is greater than the number of kinases\"\n",
    "assert K <= num_our_kins, \"K is greater than the number of kinases\"\n",
    "assert np.all(our_ranks.columns == their_ranks.columns), \"Columns are not aligned\"\n",
    "assert np.all(our_ranks.index == their_ranks.index), \"Indexes are not aligned\"\n",
    "confusion_matrix = pd.DataFrame(np.zeros((num_their_kins, num_our_kins)))\n",
    "confusion_matrix.columns = pd.Series(their_ranks.columns).apply(lambda x: x.replace(\"\", \"\"))\n",
    "confusion_matrix.index = pd.Index(pd.Series(our_ranks.columns).apply(lambda x: x.replace(\"\", \"\")))\n",
    "# Make sure the two dataframes of ranks have indexes exactly the same and aligned\n",
    "for i, r in tqdm.tqdm(our_ranks.iterrows(), total = len(our_ranks.index)):\n",
    "    # Get the ranks of the site for each kinase\n",
    "    assert(isinstance(i, str))\n",
    "    our_ranks_for_site_argsort = np.argsort(np.asarray(r.values))\n",
    "    their_ranks_for_site_argsort = np.argsort(np.asarray(their_ranks.loc[i].values))\n",
    "    for k in range(K):\n",
    "        our_kth_kinase = our_ranks.columns[our_ranks_for_site_argsort[k]]\n",
    "        their_kth_kinase = their_ranks.columns[their_ranks_for_site_argsort[k]]\n",
    "        # Increment the cell (their_kinase, our_kinase) in the confusion matrix\n",
    "        confusion_matrix.at[our_kth_kinase, their_kth_kinase] += 1\n",
    "cm = confusion_matrix.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = metrics.ConfusionMatrixDisplay(cm, display_labels=[x.replace(\"^Pctl\", \"\").replace(\"^Rank\", \"\").replace(\"|['\", \" (\").replace(\"']\", \"\").replace(\"['\", \"\") + \")\" for x in confusion_matrix.columns.tolist()])\n",
    "a.plot(include_values=False)\n",
    "_ = plt.xticks(*plt.xticks(), rotation=90) # type: ignore\n",
    "_ = plt.ylabel(f\"Num sites with top {K} score for DeepKS model\")\n",
    "_ = plt.xlabel(f\"Num sites with top {K} score for Atlas model\")\n",
    "_ = plt.title(f\"Confusion Matrix\")\n",
    "# _ = plt.gca().set_title(\"Num Sites\")\n",
    "plt.gcf().axes[1].set_title(\"Num Sites\", loc='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get distance between ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 3\n",
    "\n",
    "# random simulation\n",
    "base = list(range(1, 11))\n",
    "many_sites_A = [random.sample(base, k=10) for _ in range(86000)]\n",
    "many_sites_B = [random.sample(base, k=10) for _ in range(86000)]\n",
    "for c in range(10):\n",
    "    dist_within_d = 0\n",
    "    dist_not_within_d = 0\n",
    "    for i, (t, o) in enumerate(zip(many_sites_A, many_sites_B)):\n",
    "        if abs(t[c] - o[c]) <= D:\n",
    "            dist_within_d += 1\n",
    "        else:\n",
    "            dist_not_within_d += 1\n",
    "    print(f\"{c=}: {dist_within_d} within {D}, {dist_not_within_d} not within {D}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare rank distributions between DeepKS and Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['font.size'] = 7\n",
    "titles = [x.replace(\"^Pctl\", \"\").replace(\"^Rank\", \"\").replace(\"|['\", \" (\").replace(\"']\", \"\").replace(\"['\", \"\") + \")\" for x in confusion_matrix.columns.tolist()]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=10, ncols=2, figsize = (4, 16), gridspec_kw={'width_ratios': [0.5, 0.5], 'hspace': 0.5, 'wspace': 0.5})\n",
    "for j, ranks in enumerate([our_ranks, their_ranks]):\n",
    "    for i, c in enumerate(ranks.columns):\n",
    "        ax[i][j].hist(ranks[c], bins=[0.5+x for x in range(11)], color='blue', alpha=0.5, align='mid', density=True)\n",
    "        ax[i][j].set_xlim(0.5, 10.5)\n",
    "        ax[i][j].set_ylabel(\"Density\")\n",
    "        ax[i][j].set_yticks([], [])\n",
    "        ax[i][j].set_xticks(range(1, 11), [str(x) for x in range(1, 11)])\n",
    "        ax[i][j].set_title(f\"{titles[i]} — {'DeepKS' if j == 0 else 'Atlas'}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get distributions and QQ plots of our raw scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from scipy.stats.distributions import norm\n",
    "from scipy import stats\n",
    "import sys\n",
    "sys.stderr = open(\"/dev/null\", \"w\")\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "KINS = our_raw_scores.columns\n",
    "# Check distribution of raw scores for KIN\n",
    "fig, axs = plt.subplots(nrows=len(KINS), ncols=2, figsize=(5, len(KINS)*3.5), gridspec_kw={'hspace': 0.3, 'wspace': 0.4})\n",
    "for i, KIN in enumerate(KINS):\n",
    "    hist_info = axs[i][0].hist(our_raw_scores[KIN], bins=50, density=False)\n",
    "    _ = axs[i][0].set_xlim(0, 1)\n",
    "    _ = axs[i][0].set_ylim(0, 10000)\n",
    "    _ = axs[i][0].set_title(str(KIN).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").replace(\" \", \"\").replace(\"^Score\", \"\").replace(\"|\", \" (\") + \")\")\n",
    "    _ = axs[i][0].set_yticks([], [])\n",
    "    _ = axs[i][0].set_xlabel(\"Score\" if i == 0 else \"\")\n",
    "    _ = axs[i][0].set_ylabel(\"Num sites\" if i == 0 else \"\")\n",
    "    _ = axs[i][0].set_yticks([0, 2500, 5000, 7500, 10000] if i == 0 else [0, 10000], [0, 2500, 5000, 7500, 10000] if i == 0 else [0, 10000])\n",
    "    _ = axs[i][0].set_xticks([0, 0.25, 0.5, 0.75, 1] if i == 0 else [0, 1], [0, 0.25, 0.5, 0.75, 1] if i == 0 else [0, 1])\n",
    "    max_hist_value = max(hist_info[0])\n",
    "    X = np.linspace(0, 1, 1000)\n",
    "    Y = (norm.pdf(np.linspace(0, 1, 1000), loc=np.mean(our_raw_scores[KIN]), scale=np.std(our_raw_scores[KIN]))*len(our_raw_scores[KIN]))\n",
    "    _ = axs[i][0].plot(X, Y/(max(Y)/max_hist_value), color='red')\n",
    "    modified_comparison = lambda: norm(loc=np.mean(our_raw_scores[KIN]), scale=np.std(our_raw_scores[KIN]))\n",
    "    _ = stats.probplot(random.sample(our_raw_scores[KIN].tolist(), k=500), sparams = (np.mean(our_raw_scores[KIN]), np.std(our_raw_scores[KIN])), plot=axs[i][1])\n",
    "    _ = axs[i][1].set_title(\"QQ Plot\")\n",
    "    _ = axs[i][1].set_xlabel(\"Observed Quantiles\" if i == 0 else \"\")\n",
    "    _ = axs[i][1].set_ylabel(\"Theoretical Quantiles\" if i == 0 else \"\")\n",
    "    if i != 0:\n",
    "        _ = axs[i][1].set_yticks([0, 2500, 5000, 7500, 10000] if i == 0 else [], [0, 2500, 5000, 7500, 10000] if i == 0 else [])\n",
    "        _ = axs[i][1].set_xticks([0, 0.25, 0.5, 0.75, 1] if i == 0 else [], [0, 0.25, 0.5, 0.75, 1] if i == 0 else [])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make scatterplot of percentile vs. percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(our_percentiles) == len(their_percentiles), \"The number of sites is not the same between our percentiles and their percentiles\"\n",
    "assert set(our_percentiles.index) == set(their_percentiles.index), \"The set of indices (symbols) is not the same between our percentiles and their percentiles\"\n",
    "assert np.all(their_percentiles.index == our_percentiles.index), \"The order of indices (symbols) is not the same between our percentiles and their percentiles\"\n",
    "\n",
    "fig = plt.figure(figsize=(6, 8))\n",
    "\n",
    "KIN = str(their_percentiles.columns[5])\n",
    "inds = list(range(len(their_percentiles[KIN])))\n",
    "inds = random.sample(inds, k=1000)\n",
    "_ = plt.gca().set_aspect(1)\n",
    "X = our_percentiles[KIN.replace(\"]^Pctl\", \"]^Score\")].tolist()\n",
    "X = [X[i] for i in inds]\n",
    "Y = their_percentiles[KIN].tolist()\n",
    "Y = [Y[i] for i in inds]\n",
    "plt.scatter(X, Y, label=\"One Site\", marker=MarkerStyle(\"o\"), s=2)\n",
    "plt.xlabel(\"Our Percentiles\")\n",
    "plt.ylabel(\"Atlas Percentiles\")\n",
    "nice_kin = KIN.replace(\"|['\", \" (\").replace(\"]\", \"\").replace(\"'\", \"\").replace(\"^Pctl\", \"\").replace(\"[\", \"\") + \")\"\n",
    "the_title = tw.fill(f\"Comparing Atlas vs. DeepKS on Percentile-Score of each site for \" + nice_kin, width=50, replace_whitespace=False)\n",
    "the_subtitle = tw.fill(\"\\n(I.e., the percentile in the distribution of scores between each site and \"+ nice_kin.split(\" \")[0] + \")\", width=50, replace_whitespace=False)\n",
    "\n",
    "plt.title(the_title, y = 1.1)\n",
    "plt.suptitle(the_subtitle, fontsize=10, y = 0.85)\n",
    "_ = plt.legend(loc=\"lower right\", fancybox=True, shadow=True, title=\"Legend\", markerscale=3, title_fontproperties = {'size': 12, 'weight': 'bold'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make scatterplot of rank vs. rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 9))\n",
    "\n",
    "KIN = str(their_ranks.columns[5])\n",
    "inds = list(range(len(their_ranks[KIN])))\n",
    "inds = random.sample(inds, k=1000)\n",
    "_ = plt.gca().set_aspect(1)\n",
    "X = our_ranks[KIN].tolist()\n",
    "X = [X[i] for i in inds]\n",
    "Y = their_ranks[KIN].tolist()\n",
    "Y = [Y[i] for i in inds]\n",
    "coord_to_count = collections.Counter((i, j) for i, j in zip(X, Y))\n",
    "coord_to_size = {(i, j): coord_to_count[(i, j)] for i in range(1, 11) for j in range(1, 11)}\n",
    "plt.scatter(X, Y, label=\"Sites (Marker\\nSize ∝ Count)\", marker=MarkerStyle('o'), s=[coord_to_size[(i, j)] for i, j in zip(X, Y)])\n",
    "plt.xlabel(\"Our Ranks\")\n",
    "plt.ylabel(\"Atlas Ranks\")\n",
    "nice_kin = KIN.replace(\"|['\", \" (\").replace(\"]\", \"\").replace(\"'\", \"\").replace(\"^Rank^Pctl\", \"\").replace(\"[\", \"\") + \")\"\n",
    "the_title = tw.fill(f\"Comparing Atlas vs. DeepKS on Rank of Percentile-Scores of each site for \" + nice_kin, width=50, replace_whitespace=False)\n",
    "the_subtitle = tw.fill(\"\\n(I.e., the rank of “the percentile in the distribution of scores between each site and \"+ nice_kin.split(\" \")[0] + \"” in the set of all 10 Kinases)\", width=50, replace_whitespace=False)\n",
    "\n",
    "plt.title(the_title, y = 1.15, fontdict={'weight': 'bold', 'size': 13})\n",
    "plt.suptitle(the_subtitle, fontsize=10, y = 0.84)\n",
    "plt.plot([0, 11], [0, 11], color='red', linestyle='-', linewidth=10, label='Desired Density', alpha=0.35, solid_capstyle='round')\n",
    "_ = plt.legend(loc=\"lower right\", shadow=False, fancybox=True, title=\"Legend\", scatterpoints = 1, title_fontproperties = {'size': 12, 'weight': 'bold'}, edgecolor='black', framealpha=0.9)\n",
    "plt.xlim(-1.5, 11.5)\n",
    "plt.ylim(-1.5, 11.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
