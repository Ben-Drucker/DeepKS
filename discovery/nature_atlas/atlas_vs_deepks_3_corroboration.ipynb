{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, matplotlib.pyplot as plt, re, os, itertools, collections, tqdm, textwrap, numpy as np\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = \"P052\"\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many sites PSP and atlas have in common from the files /Users/druc594/Library/CloudStorage/OneDrive-PNNL/Desktop/DeepKS_/DeepKS/discovery/nature_atlas/site_list_86201.txt and /Users/druc594/Library/CloudStorage/OneDrive-PNNL/Desktop/DeepKS_/DeepKS/discovery/nature_atlas/PSP_site_list.csv\n",
    "\n",
    "# Read in the site list from the atlas\n",
    "site_list_atlas = pd.read_csv('/Users/druc594/Library/CloudStorage/OneDrive-PNNL/Desktop/DeepKS_/DeepKS/discovery/nature_atlas/site_list_86201.txt', header=None)\n",
    "site_list_psp = pd.read_csv('/Users/druc594/Library/CloudStorage/OneDrive-PNNL/Desktop/DeepKS_/DeepKS/discovery/nature_atlas/PSP_site_list.csv', header=None)\n",
    "# Create a Venn diagram from the two lists\n",
    "from matplotlib_venn import venn2\n",
    "venn2([set(site_list_atlas[0]), set(site_list_psp[0])], set_labels = ('Atlas', 'PSP'))\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since there is no overlap, we have to scrape from the Nature Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assume we have already run scrape.py\n",
    "\n",
    "# Open all files in scraped directory and create a mapping from site name to results table\n",
    "scraped_path = '/Users/druc594/Downloads/KinLibDown'\n",
    "mapping = {}\n",
    "for file in tqdm.tqdm([x for x in os.listdir(scraped_path) if x.endswith('.tsv')]):\n",
    "    site_name = \"\"\n",
    "    tab = None\n",
    "    try:\n",
    "        tab = pd.read_csv(os.path.join(scraped_path, file), sep='\\t')\n",
    "        site_name = re.sub(r'-[0-9]+`[0-9]+\\.tsv', '', file)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Problem:\", file)\n",
    "    \n",
    "    mapping[site_name] = tab\n",
    "        \n",
    "for k, v in mapping.items():\n",
    "    mapping[k] = v.set_index(\"kinase\").to_dict()['site_percentile']\n",
    "THEIR_RESULTS_FILE = \"./41586_2022_5575_MOESM5_ESM.csv\"\n",
    "their_results = pd.read_csv(THEIR_RESULTS_FILE).set_index(\"Uniprot Primary Accession\")\n",
    "matrix_name_to_uniprot_id: dict[str, str] = (\n",
    "    pd.read_csv(\"./41586_2022_5575_MOESM3_ESM.csv\").set_index(\"Matrix_name\").to_dict()[\"Uniprot id\"]\n",
    ")\n",
    "\n",
    "uniprot_id_to_matrix_name = {v: k for k, v in matrix_name_to_uniprot_id.items()}\n",
    "assert len(uniprot_id_to_matrix_name) == len(matrix_name_to_uniprot_id)\n",
    "kin_uniprot_to_sites = collections.defaultdict(list[str])\n",
    "psp = pd.read_excel(\"/Users/druc594/Library/CloudStorage/OneDrive-PNNL/Desktop/DeepKS_/DeepKS/data/raw_data/PSP_script_download.xlsx\")[[\"SITE_+/-7_AA\", \"KIN_ACC_ID\"]]\n",
    "\n",
    "for _, row in psp.iterrows():\n",
    "    assert isinstance(row[\"SITE_+/-7_AA\"], str)\n",
    "    kin_uniprot_to_sites[row[\"KIN_ACC_ID\"]].append(re.sub(r\"^(.{8})\", r\"\\1*\", row[\"SITE_+/-7_AA\"].upper()))\n",
    "mod_cols = set([matrix_name_to_uniprot_id[re.sub(r\"^([0-9A-Z]+)_rank.*\", r\"\\1\", x)] for x in their_results.columns if x.endswith(\"_rank\")])\n",
    "kuts = kin_uniprot_to_sites.copy().keys()\n",
    "\n",
    "for kin_u in kuts:\n",
    "    if kin_u not in mod_cols:\n",
    "        kin_uniprot_to_sites.pop(kin_u)\n",
    "site_to_kin_uniprots = collections.defaultdict(list[str])\n",
    "\n",
    "for kin_u, sites in kin_uniprot_to_sites.items():\n",
    "    for site in sites:\n",
    "        site_to_kin_uniprots[site].append(kin_u)\n",
    "\n",
    "site_to_kin_uniprots_shortened = {k.replace(\"*\", \"\")[2:-1].replace(\"_\", \"\"):v for k,v in site_to_kin_uniprots.items()}\n",
    "site_to_percentiles = collections.defaultdict(list[float])\n",
    "\n",
    "# Build up a mapping from site to list of percentiles\n",
    "for site in mapping:\n",
    "    assert site in site_to_kin_uniprots_shortened, f\"{site} not in site_to_kin_uniprots_shortened\"\n",
    "    for kin in site_to_kin_uniprots_shortened[site]:\n",
    "        assert kin in uniprot_id_to_matrix_name, f\"{kin} not in uniprot_id_to_matrix_name\"\n",
    "        assert site in mapping, f\"{site} not in mapping\"\n",
    "        if uniprot_id_to_matrix_name[kin] in mapping[site]:\n",
    "            site_to_percentiles[site].append(mapping[site][uniprot_id_to_matrix_name[kin]])\n",
    "            \n",
    "all_percentiles = list(itertools.chain(*site_to_percentiles.values()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a histogram of the percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n",
    "max_height = 0\n",
    "hist_data = ax.hist(all_percentiles, bins=list(range(0, 101, 5)))\n",
    "this_max_height = max(hist_data[0])\n",
    "assert isinstance(this_max_height, float)\n",
    "max_height = max(max_height, this_max_height)\n",
    "max_height = np.ceil(max_height / 5) * 5\n",
    "ax.set_title(\n",
    "    textwrap.fill(\n",
    "        (\n",
    "            f\"Distribution of Atlas-predicted percentiles for {len(all_percentiles)} experimentally validated PSP K-S\"\n",
    "            \" pairs\"\n",
    "        ),\n",
    "        120,\n",
    "    )\n",
    ")\n",
    "ax.set_xlabel(\"Percentile\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_xticks([1], [f\"{len(all_percentiles)} pairs\"])\n",
    "ax.set_xticks(range(0, 101, 10), range(0, 101, 10))\n",
    "ax.set_ylim(0, min(4 + max_height, max_height * 1.1))\n",
    "print(max_height)\n",
    "ytk = range(0, int(max_height) + 1, int(5*np.floor(np.log10(max_height))))\n",
    "ax.set_yticks(ytk, ytk)\n",
    "_ = ax.grid(visible=True, axis=\"y\", linestyle=\"--\", alpha=0.4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a boxplot of the percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows = 1, ncols = 1, figsize = (3, 7))\n",
    "max_height = 0\n",
    "ax.boxplot(all_percentiles)\n",
    "# this_max_height = max(hist_data[0])\n",
    "# assert isinstance(this_max_height, float)\n",
    "# max_height = max(max_height, this_max_height)\n",
    "# max_height = np.ceil(max_height/5) * 5\n",
    "ax.set_title(textwrap.fill(f\"Distribution of Atlas-predicted percentiles for {len(all_percentiles)} experimentally validated PSP K-S pairs\", 40))\n",
    "# ax.set_xlabel(\"Percentile\")\n",
    "ax.set_ylabel(\"Percentile\")\n",
    "ax.set_xticks([1], [f\"{len(all_percentiles)} pairs\"])\n",
    "# ax.set_xticks(range(0, 101, 10), range(0, 101, 10))\n",
    "# ax.set_ylim(0, min(4 + max_height, max_height*1.1))\n",
    "# print(max_height)\n",
    "_ = ax.set_yticks(range(0, 101, 10))\n",
    "ax.grid(visible=True, axis = 'y', linestyle=\"--\", alpha=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
